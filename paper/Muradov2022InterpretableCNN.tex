\documentclass[12pt]{article}
\usepackage{arxiv}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{mathtools}




\title{Выбор интерпретируемых сверточных моделей глубокого обучения}

\author{ Тимур Мурадов\\
	МФТИ\\
	\And
	Олег Бахтеев \\
	МФТИ\\
	\And
	Константин Яковлев \\
	МФТИ\\
	\And
	Вадим Стрижов \\
	МФТИ\\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{}

\renewcommand{\undertitle}{}
\renewcommand{\headeright}{}
\renewcommand{\shorttitle}{Выбор интерпретируемых сверточных моделей глубокого обучения}

\hypersetup{
pdftitle={Выбор интерпретируемых сверточных моделей глубокого обучения},
pdfauthor={Тимур Мурадов},
pdfkeywords={Model interpretability \and Deep Learning \and OpenBox \and Convolutional neural networks},
}


\begin{document}
\maketitle

\begin{abstract}
	В статье рассматривается задача построения интерпретируемой сверточной нейронной сети. Под интерпретируемостью модели понимается выделение наиболее важных признаков и определение кластеров схожих объектов. Для повышения интерпретируемоси в статье вводится модификация метода OpenBox работающего с  кусочно-линейными нейронными сетями. В нём модель представляется в виде набора интерпретируемых линейных классификаторов. Каждый из них определен на выпуклом многограннике. Это позволяет классифицировать схожие объекты одним и тем же классификатором. Метод обобщается на работу с более широким классом нейронных сетей: сверточными нейронными сетями. Предлагается математически эквивалентная замена слоев свёрточной сети на линейные модели. Что  значительно повышает интепретируемость. Вычислительный эксперимент проводится на выборках изображений рукописных цифр MNIST и изображений CIFAR-10.
\end{abstract}


\keywords{Model interpretability \and Deep Learning \and OpenBox \and Convolutional neural networks}

\section{Introduction}
В данном исследовании стоит задача повышения интерпретируемости модели, где под интерпретируемостью понимается простота выделения важных признаков на выборке данных и классификация близких объектов одним и тем же классификатором.

Проблемой является в целом высокая сложность интерпретации сверточных нейронных сетей, требующая комплексного подхода. На данный момент существует множество различных решений проблемы интерпретации \cite{ribeiro2016why, Lundberg2017aunified, chu2019exact} . В статье \cite{ribeiro2016why} описан метод \textbf{LIME}, предлагащий линейную апроксимацию предсказаний модели в некоторой небольшой окрестности вокруг объектов из тестовой выборки. Такой подход позволяет получить простую для интерпретации модель без использования информации о строении модели изнутри \textquotedblleft model-agnostic\textquotedblright. Но он весьма неустойчив к выбросам и сильно зависим от точности апроксимации. В статье \cite{Lundberg2017aunified} предлагается подход \textbf{SHAP}, заключающийся в рассмотрении вклада каждого признака в работу модели. Таким образом удается выделять даже скрытые, но значимые признаки. Однако применимость данного подхода ограничена ввиду высоких вычислительных затрат: требуется многократное обучение модели, и он весьма зависим от выборки данных. Ещё один подход к интерпретации \textbf{OpenBox}, описываемый в статье \cite{chu2019exact} предлагает построение математически эквивалентных линейных моделей для линейных нейронных сетей. Он показал более высокую эффективность по сравнению с \textbf{LIME} и весьма перспективен для дальнейшей работы.

В данной работе предлагается адаптация метода \textbf{OpenBox} для работы со свёрточными нейронными сетями: математически эквивалентно представить в виде линейных моделей такие слои как свёртка, пулинг и нормализация. И сравнение с альтернативными методами интепретации CNN.

Для анализа качества предложенного метода проводится вычислительный эксперимент на выборке изображений Fashion-MNIST \citep{fashionmnist}.



\section{Problem Definition}
\label{sec:headings}

Задана выборка $x \in \mathbf{X}$ двумерные трехканальные изображения. $\mathbf{X} \in \{1, 2, ... k\}$, заданное конечное множество классов.

Рассматривается задача построения модели глубокого обучения для задачи классификации.

Модель $f(X, w)$ - сверточная нейронная сеть, для краткости CNN, это суперпозиция подмоделей $f_1 \circ f_2 \dots f_n$.

Функции $f_i$ - слои нейронной сети, это одни из функций: линейные $y_i = w_0 + \Sigma w_i * x_i$, свертки, батч-нормы или пулинги.

$f(X, w)$ оптимизирует функцию кросс энтропии $\mathcal{L}$, $g$ - функция softmax.

$$g(x)_i = \frac{e^{x_i}}{\Sigma_j e^{x_j}}$$
$$\mathcal{L} = -\Sigma_i \log g(x)_i \to \max$$

Кроме задачи оптимизации модель также должна удовлетворять следующим требованиям к итерпретируемости: $\textbf{Точность}$ и $\textbf{Консистентность}$.
\begin{itemize}
    \item \textbf{Точность}:
    Математическая эквивалентность.
    \item \textbf{Консистентность}:
    Близкие интерпретации для близких объектов выборки.
\end{itemize}

\section{Our setup}

Строим CNN и при помощи метода LIME \cite{ribeiro2016why} получаем интерпретации признаков модели.

\section{Computational experiment}

Эксперимент заключается в получении baseline качества интрепретаций для дальнейшего исследования.

\subsection{Data}

  Fashion-MNIST датасет содержащий 60000 изображений в train и 10000 изображений в test из 10 различных классов. Каждое изображение имеет разрешение 28*28 пикселей  \citep{fashionmnist}.

\subsection{Configuration of algorithm run}

Считаем точность предсказаний и расстояние между признаками, полученные при помощи алгоритма LIME \cite{ribeiro2016why}.

\subsection{Preliminary report}


\begin{figure}[!t]
  \subfloat{\includegraphics[width=0.5\textwidth]{../figures/accuracy.png}}
  \subfloat{\includegraphics[width=0.5\textwidth]{../figures/similarity.png}}\\
 \caption{Accuracy and cosine similarity between decision features}
  \label{fig:1}
\end{figure}

\newpage

\bibliographystyle{unsrt}
\bibliography{ref}

\end{document}